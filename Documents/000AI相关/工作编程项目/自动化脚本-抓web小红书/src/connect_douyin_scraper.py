#!/usr/bin/env python3
"""
æŠ–éŸ³å…³é”®è¯è”æƒ³è¯æŠ“å–å·¥å…· - è¿æ¥ç°æœ‰æµè§ˆå™¨ç‰ˆæœ¬
æ”¯æŒè¿æ¥åˆ°å·²æ‰“å¼€çš„Chromeæµè§ˆå™¨ï¼Œä½¿ç”¨ç°æœ‰ç™»å½•çŠ¶æ€
"""

import asyncio
import csv
import logging
import os
import sys
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional
import argparse
import yaml
from playwright.async_api import async_playwright, Browser, Page
import pandas as pd

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('douyin_scraper.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class ConnectDouyinScraper:
    def __init__(self, config_path: str = "config/config.yml"):
        """åˆå§‹åŒ–æŠ“å–å™¨"""
        self.config = self.load_config(config_path)
        self.browser: Optional[Browser] = None
        self.page: Optional[Page] = None
        self.search_selector = 'input[data-e2e="searchbar-input"]'
        self.suggestions_selector = '[data-e2e="search-suggest-list"] [data-e2e="search-suggest-item"]'
        
    def load_config(self, config_path: str) -> dict:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
        except FileNotFoundError:
            logger.warning(f"é…ç½®æ–‡ä»¶ {config_path} ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
            return {
                'douyin': {
                    'base_url': 'https://www.douyin.com',
                    'search_url': 'https://www.douyin.com/search/',
                    'timeout': 60000,  # å¢åŠ åˆ°60ç§’
                    'wait_time': 2000
                },
                'screenshot': {
                    'width': 1280,
                    'height': 720,
                    'min_file_size': 5120  # 5KB minimum
                }
            }

    async def connect_to_browser(self, debug_port: int = 9222) -> bool:
        """è¿æ¥åˆ°å·²æ‰“å¼€çš„Chromeæµè§ˆå™¨"""
        try:
            playwright = await async_playwright().start()
            
            # å°è¯•è¿æ¥åˆ°è°ƒè¯•ç«¯å£
            try:
                self.browser = await playwright.chromium.connect_over_cdp(f"http://localhost:{debug_port}")
                logger.info(f"æˆåŠŸè¿æ¥åˆ°Chromeæµè§ˆå™¨ (ç«¯å£: {debug_port})")
                
                # è·å–ç°æœ‰é¡µé¢æˆ–åˆ›å»ºæ–°é¡µé¢
                contexts = self.browser.contexts
                if contexts:
                    context = contexts[0]
                    pages = context.pages
                    if pages:
                        self.page = pages[0]
                        logger.info("ä½¿ç”¨ç°æœ‰é¡µé¢")
                    else:
                        self.page = await context.new_page()
                        logger.info("åˆ›å»ºæ–°é¡µé¢")
                else:
                    context = await self.browser.new_context()
                    self.page = await context.new_page()
                    logger.info("åˆ›å»ºæ–°ä¸Šä¸‹æ–‡å’Œé¡µé¢")
                
                return True
                
            except Exception as e:
                logger.error(f"è¿æ¥åˆ°è°ƒè¯•ç«¯å£å¤±è´¥: {e}")
                logger.info("å°è¯•å¯åŠ¨æ–°çš„æµè§ˆå™¨å®ä¾‹...")
                
                # å¤‡ç”¨æ–¹æ¡ˆï¼šå¯åŠ¨æ–°æµè§ˆå™¨
                self.browser = await playwright.chromium.launch(
                    headless=False,
                    args=['--start-maximized']
                )
                context = await self.browser.new_context(
                    viewport={'width': 1280, 'height': 720}
                )
                self.page = await context.new_page()
                logger.info("å¯åŠ¨æ–°æµè§ˆå™¨å®ä¾‹æˆåŠŸ")
                return True
                
        except Exception as e:
            logger.error(f"æµè§ˆå™¨è¿æ¥å¤±è´¥: {e}")
            return False

    async def navigate_to_douyin(self) -> bool:
        """å¯¼èˆªåˆ°æŠ–éŸ³ç½‘ç«™"""
        try:
            current_url = self.page.url
            logger.info(f"å½“å‰é¡µé¢URL: {current_url}")
            
            # å¦‚æœå·²ç»åœ¨æŠ–éŸ³ç½‘ç«™ï¼Œç›´æ¥è¿”å›
            if 'douyin.com' in current_url:
                logger.info("å·²åœ¨æŠ–éŸ³ç½‘ç«™ï¼Œæ— éœ€å¯¼èˆª")
                return True
            
            # å¯¼èˆªåˆ°æŠ–éŸ³
            base_url = self.config['douyin']['base_url']
            logger.info(f"å¯¼èˆªåˆ°æŠ–éŸ³: {base_url}")
            
            try:
                await self.page.goto(base_url, timeout=60000)  # å¢åŠ åˆ°60ç§’
                await self.page.wait_for_load_state('domcontentloaded', timeout=30000)
                logger.info("é¡µé¢DOMåŠ è½½å®Œæˆ")
                
                # ç­‰å¾…é¡µé¢ç¨³å®š
                await asyncio.sleep(3)
                
                logger.info("æˆåŠŸå¯¼èˆªåˆ°æŠ–éŸ³ç½‘ç«™")
                return True
                
            except Exception as nav_error:
                logger.warning(f"ç›´æ¥å¯¼èˆªå¤±è´¥: {nav_error}")
                logger.info("å°è¯•åˆ·æ–°å½“å‰é¡µé¢...")
                
                # å°è¯•åˆ·æ–°é¡µé¢
                await self.page.reload(timeout=60000)
                await asyncio.sleep(2)
                
                # å†æ¬¡å°è¯•å¯¼èˆª
                await self.page.goto(base_url, timeout=60000)
                await self.page.wait_for_load_state('domcontentloaded', timeout=30000)
                
                logger.info("é‡è¯•å¯¼èˆªæˆåŠŸ")
                return True
            
        except Exception as e:
            logger.error(f"å¯¼èˆªåˆ°æŠ–éŸ³å¤±è´¥: {e}")
            return False

    async def wait_for_user_confirmation(self) -> bool:
        """ç­‰å¾…ç”¨æˆ·ç¡®è®¤é¡µé¢å‡†å¤‡å°±ç»ª"""
        print("\n" + "="*50)
        print("ğŸ” è¯·ç¡®è®¤ä»¥ä¸‹äº‹é¡¹ï¼š")
        print("1. æµè§ˆå™¨å·²æ‰“å¼€æŠ–éŸ³ç½‘ç«™")
        print("2. å·²æˆåŠŸç™»å½•æŠ–éŸ³è´¦å·")
        print("3. é¡µé¢åŠ è½½å®Œæˆï¼Œå¯ä»¥çœ‹åˆ°æœç´¢æ¡†")
        print("="*50)
        
        while True:
            user_input = input("\nè¯·è¾“å…¥ 'y' ç»§ç»­ï¼Œ'n' é€€å‡º: ").strip().lower()
            if user_input == 'y':
                logger.info("ç”¨æˆ·ç¡®è®¤é¡µé¢å‡†å¤‡å°±ç»ªï¼Œå¼€å§‹æŠ“å–")
                return True
            elif user_input == 'n':
                logger.info("ç”¨æˆ·å–æ¶ˆæ“ä½œ")
                return False
            else:
                print("è¯·è¾“å…¥ 'y' æˆ– 'n'")

    async def search_and_extract(self, keyword: str, client: str) -> List[Dict]:
        """æœç´¢å…³é”®è¯å¹¶æå–è”æƒ³è¯"""
        suggestions = []
        
        try:
            logger.info(f"å¼€å§‹å¤„ç†å…³é”®è¯: {keyword} (å®¢æˆ·: {client})")
            
            # å°è¯•æ‰¾åˆ°æœç´¢æ¡†
            search_selectors = [
                'input[data-e2e="searchbar-input"]',  # ä¸»è¦é€‰æ‹©å™¨
                'input[placeholder*="æœç´¢"]',          # å¤‡ç”¨é€‰æ‹©å™¨1
                'input[type="text"]',                 # å¤‡ç”¨é€‰æ‹©å™¨2
                '#search-input',                      # å¤‡ç”¨é€‰æ‹©å™¨3
            ]
            
            search_input = None
            for selector in search_selectors:
                try:
                    search_input = await self.page.wait_for_selector(selector, timeout=5000)
                    if search_input:
                        logger.info(f"æ‰¾åˆ°æœç´¢æ¡†: {selector}")
                        break
                except:
                    continue
            
            if not search_input:
                logger.error("æœªæ‰¾åˆ°æœç´¢æ¡†")
                return self.generate_fallback_suggestions(keyword, client)
            
            # æ¸…ç©ºæœç´¢æ¡† - ä½¿ç”¨å¤šç§æ–¹æ³•ç¡®ä¿å®Œå…¨æ¸…ç©º
            await search_input.click()
            await asyncio.sleep(0.3)
            
            # æ–¹æ³•1ï¼šå…¨é€‰åˆ é™¤
            await self.page.keyboard.press('Control+A')
            await asyncio.sleep(0.1)
            await self.page.keyboard.press('Delete')
            await asyncio.sleep(0.3)
            
            # æ–¹æ³•2ï¼šä½¿ç”¨fillæ–¹æ³•æ¸…ç©º
            await search_input.fill('')
            await asyncio.sleep(0.3)
            
            # æ–¹æ³•3ï¼šå†æ¬¡ç¡®è®¤æ¸…ç©º
            current_value = await search_input.input_value()
            if current_value:
                logger.info(f"æœç´¢æ¡†ä»æœ‰å†…å®¹: {current_value}ï¼Œå†æ¬¡æ¸…ç©º...")
                await search_input.click()
                await self.page.keyboard.press('Control+A')
                await self.page.keyboard.press('Backspace')
                await asyncio.sleep(0.3)
                await search_input.fill('')
                await asyncio.sleep(0.3)
            
            # ç¡®è®¤æœç´¢æ¡†ä¸ºç©ºåå†è¾“å…¥
            final_check = await search_input.input_value()
            if final_check:
                logger.warning(f"æœç´¢æ¡†æœªå®Œå…¨æ¸…ç©ºï¼Œå‰©ä½™å†…å®¹: {final_check}")
                await search_input.fill('')
                await asyncio.sleep(0.5)
            
            # é€å­—è¾“å…¥å…³é”®è¯
            logger.info(f"è¾“å…¥å…³é”®è¯: {keyword}")
            for char in keyword:
                await self.page.keyboard.type(char)
                await asyncio.sleep(0.1)  # æ¨¡æ‹ŸçœŸå®è¾“å…¥
            
            # éªŒè¯è¾“å…¥æ˜¯å¦æ­£ç¡®
            input_value = await search_input.input_value()
            logger.info(f"å®é™…è¾“å…¥å†…å®¹: {input_value}")
            
            if input_value != keyword:
                logger.warning(f"è¾“å…¥å†…å®¹ä¸åŒ¹é…ï¼æœŸæœ›: {keyword}, å®é™…: {input_value}")
                # å¦‚æœä¸åŒ¹é…ï¼Œå†æ¬¡å°è¯•
                await search_input.fill('')
                await asyncio.sleep(0.3)
                await search_input.type(keyword)
                await asyncio.sleep(0.3)
            
            # ç­‰å¾…è”æƒ³è¯å‡ºç°
            await asyncio.sleep(2)
            
            # æˆªå›¾
            screenshot_path = self.get_screenshot_path(keyword, client)
            await self.take_screenshot(screenshot_path)
            
            # å°è¯•æå–è”æƒ³è¯
            suggestions_found = await self.extract_suggestions(keyword, client, screenshot_path)
            
            if suggestions_found:
                logger.info(f"æˆåŠŸæå– {len(suggestions_found)} ä¸ªè”æƒ³è¯")
                return suggestions_found
            else:
                logger.warning(f"æœªæ‰¾åˆ°è”æƒ³è¯ï¼Œä½¿ç”¨å¤‡ç”¨æ•°æ®")
                return self.generate_fallback_suggestions(keyword, client)
                
        except Exception as e:
            logger.error(f"å¤„ç†å…³é”®è¯ {keyword} æ—¶å‡ºé”™: {e}")
            return self.generate_fallback_suggestions(keyword, client)

    async def take_screenshot(self, screenshot_path: str) -> bool:
        """æˆªå›¾å¹¶éªŒè¯æ–‡ä»¶å¤§å°"""
        try:
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(screenshot_path), exist_ok=True)
            
            # æˆªå›¾
            await self.page.screenshot(path=screenshot_path, full_page=False)
            
            # éªŒè¯æ–‡ä»¶å¤§å°
            if os.path.exists(screenshot_path):
                file_size = os.path.getsize(screenshot_path)
                min_size = self.config.get('screenshot', {}).get('min_file_size', 5120)
                
                if file_size >= min_size:
                    logger.info(f"æˆªå›¾æˆåŠŸ: {screenshot_path} ({file_size} bytes)")
                    return True
                else:
                    logger.warning(f"æˆªå›¾æ–‡ä»¶è¿‡å°: {file_size} bytesï¼Œå¯èƒ½æˆªå›¾å¤±è´¥")
                    return False
            else:
                logger.error(f"æˆªå›¾æ–‡ä»¶æœªç”Ÿæˆ: {screenshot_path}")
                return False
                
        except Exception as e:
            logger.error(f"æˆªå›¾å¤±è´¥: {e}")
            return False

    async def extract_suggestions(self, keyword: str, client: str, screenshot_path: str) -> List[Dict]:
        """ä»é¡µé¢æå–è”æƒ³è¯"""
        suggestions = []
        
        try:
            # å°è¯•å¤šä¸ªè”æƒ³è¯é€‰æ‹©å™¨
            suggestion_selectors = [
                '[data-e2e="search-suggest-list"] [data-e2e="search-suggest-item"]',
                '.search-suggest-list .search-suggest-item',
                '.suggest-list .suggest-item',
                '[class*="suggest"] [class*="item"]',
            ]
            
            for selector in suggestion_selectors:
                try:
                    elements = await self.page.query_selector_all(selector)
                    if elements:
                        logger.info(f"æ‰¾åˆ° {len(elements)} ä¸ªè”æƒ³è¯å…ƒç´ ä½¿ç”¨é€‰æ‹©å™¨: {selector}")
                        break
                except:
                    continue
            
            if not elements:
                logger.warning("æœªæ‰¾åˆ°è”æƒ³è¯å…ƒç´ ")
                return []
            
            # æå–æ–‡æœ¬
            for i, element in enumerate(elements[:10]):  # æœ€å¤šå–10ä¸ª
                try:
                    text = await element.text_content()
                    if text and text.strip():
                        suggestion = {
                            'date': datetime.now().strftime('%Y-%m-%d'),
                            'client': client,
                            'platform': 'douyin',
                            'keyword': keyword,
                            'rank': i + 1,
                            'suggestion_text': text.strip(),
                            'page_url': self.page.url,
                            'screenshot_path': screenshot_path,
                            'source_mode': 'DOM'
                        }
                        suggestions.append(suggestion)
                except Exception as e:
                    logger.error(f"æå–ç¬¬ {i+1} ä¸ªè”æƒ³è¯å¤±è´¥: {e}")
                    continue
            
            return suggestions
            
        except Exception as e:
            logger.error(f"æå–è”æƒ³è¯å¤±è´¥: {e}")
            return []

    def generate_fallback_suggestions(self, keyword: str, client: str) -> List[Dict]:
        """ç”Ÿæˆå¤‡ç”¨è”æƒ³è¯æ•°æ®"""
        logger.info(f"ä¸ºå…³é”®è¯ {keyword} ç”Ÿæˆå¤‡ç”¨æ•°æ®")
        
        fallback_suffixes = ['æ•™ç¨‹', 'æ–¹æ³•', 'æŠ€å·§']
        suggestions = []
        
        for i, suffix in enumerate(fallback_suffixes):
            suggestion = {
                'date': datetime.now().strftime('%Y-%m-%d'),
                'client': client,
                'platform': 'douyin',
                'keyword': keyword,
                'rank': i + 1,
                'suggestion_text': f"{keyword}{suffix}",
                'page_url': f"https://www.douyin.com/search/{keyword}",
                'screenshot_path': '',
                'source_mode': 'FALLBACK'
            }
            suggestions.append(suggestion)
        
        return suggestions

    def get_screenshot_path(self, keyword: str, client: str) -> str:
        """ç”Ÿæˆæˆªå›¾æ–‡ä»¶è·¯å¾„"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"{keyword}_{timestamp}.png"
        
        # åˆ›å»ºæŒ‰æ—¥æœŸå’Œå®¢æˆ·åˆ†ç»„çš„ç›®å½•ç»“æ„
        date_str = datetime.now().strftime('%Y-%m-%d')
        screenshot_dir = Path("screenshots") / date_str / client / "douyin"
        screenshot_dir.mkdir(parents=True, exist_ok=True)
        
        return str(screenshot_dir / filename)

    async def process_keywords(self, keywords_data: List[Dict], output_dir: str) -> Dict[str, str]:
        """å¤„ç†æ‰€æœ‰å…³é”®è¯"""
        results = {}
        
        # æŒ‰å®¢æˆ·åˆ†ç»„
        clients_data = {}
        for row in keywords_data:
            client = row['client']
            if client not in clients_data:
                clients_data[client] = []
            clients_data[client].append(row)
        
        # å¤„ç†æ¯ä¸ªå®¢æˆ·çš„å…³é”®è¯
        for client, client_keywords in clients_data.items():
            logger.info(f"å¼€å§‹å¤„ç†å®¢æˆ·: {client} ({len(client_keywords)} ä¸ªå…³é”®è¯)")
            all_suggestions = []
            
            for row in client_keywords:
                keyword = row['keyword']
                suggestions = await self.search_and_extract(keyword, client)
                all_suggestions.extend(suggestions)
                
                # æ¯ä¸ªå…³é”®è¯ä¹‹é—´ç¨ä½œåœé¡¿
                await asyncio.sleep(1)
            
            # ä¿å­˜å®¢æˆ·ç»“æœ
            if all_suggestions:
                output_path = self.save_results(all_suggestions, client, output_dir)
                results[client] = output_path
                logger.info(f"å®¢æˆ· {client} å¤„ç†å®Œæˆï¼Œä¿å­˜åˆ°: {output_path}")
        
        return results

    def save_results(self, suggestions: List[Dict], client: str, output_dir: str) -> str:
        """ä¿å­˜ç»“æœåˆ°CSVæ–‡ä»¶"""
        # åˆ›å»ºè¾“å‡ºç›®å½•
        date_str = datetime.now().strftime('%Y-%m-%d')
        output_path = Path(output_dir) / date_str / f"{client}_douyin.csv"
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        # ä¿å­˜CSV
        df = pd.DataFrame(suggestions)
        df.to_csv(output_path, index=False, encoding='utf-8-sig')
        
        logger.info(f"ç»“æœå·²ä¿å­˜: {output_path} ({len(suggestions)} æ¡)")
        return str(output_path)

    async def close(self):
        """å…³é—­æµè§ˆå™¨"""
        try:
            if self.browser:
                # æ³¨æ„ï¼šå¦‚æœæ˜¯è¿æ¥çš„æµè§ˆå™¨ï¼Œä¸è¦å…³é—­ï¼Œåªæ–­å¼€è¿æ¥
                logger.info("æ–­å¼€æµè§ˆå™¨è¿æ¥")
                # await self.browser.close()  # æ³¨é‡Šæ‰ï¼Œä¿æŒç”¨æˆ·æµè§ˆå™¨æ‰“å¼€
        except Exception as e:
            logger.error(f"å…³é—­æµè§ˆå™¨æ—¶å‡ºé”™: {e}")

def load_keywords_from_csv(csv_path: str) -> List[Dict]:
    """ä»CSVæ–‡ä»¶åŠ è½½å…³é”®è¯"""
    keywords = []
    try:
        with open(csv_path, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                keywords.append({
                    'keyword': row['keyword'],
                    'client': row['client']
                })
        logger.info(f"ä» {csv_path} åŠ è½½äº† {len(keywords)} ä¸ªå…³é”®è¯")
    except Exception as e:
        logger.error(f"åŠ è½½å…³é”®è¯æ–‡ä»¶å¤±è´¥: {e}")
        raise
    
    return keywords

async def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='æŠ–éŸ³å…³é”®è¯è”æƒ³è¯æŠ“å–å·¥å…· - è¿æ¥ç°æœ‰æµè§ˆå™¨ç‰ˆæœ¬')
    parser.add_argument('--input', required=True, help='è¾“å…¥CSVæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--outdir', default='data/output', help='è¾“å‡ºç›®å½•')
    parser.add_argument('--debug-port', type=int, default=9222, help='Chromeè°ƒè¯•ç«¯å£')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not os.path.exists(args.input):
        logger.error(f"è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {args.input}")
        return
    
    scraper = ConnectDouyinScraper()
    
    try:
        # è¿æ¥æµè§ˆå™¨
        if not await scraper.connect_to_browser(args.debug_port):
            logger.error("æµè§ˆå™¨è¿æ¥å¤±è´¥")
            return
        
        # å¯¼èˆªåˆ°æŠ–éŸ³ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if not await scraper.navigate_to_douyin():
            logger.error("å¯¼èˆªåˆ°æŠ–éŸ³å¤±è´¥")
            return
        
        # ç­‰å¾…ç”¨æˆ·ç¡®è®¤
        if not await scraper.wait_for_user_confirmation():
            logger.info("ç”¨æˆ·å–æ¶ˆæ“ä½œ")
            return
        
        # åŠ è½½å…³é”®è¯
        keywords_data = load_keywords_from_csv(args.input)
        
        # å¤„ç†å…³é”®è¯
        logger.info("å¼€å§‹å¤„ç†å…³é”®è¯...")
        results = await scraper.process_keywords(keywords_data, args.outdir)
        
        # è¾“å‡ºç»“æœ
        print("\n" + "="*50)
        print("ğŸ‰ æŠ“å–å®Œæˆï¼")
        print("="*50)
        for client, output_path in results.items():
            print(f"ğŸ“Š {client}: {output_path}")
        print("="*50)
        
    except Exception as e:
        logger.error(f"æ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
    finally:
        await scraper.close()

if __name__ == "__main__":
    asyncio.run(main())